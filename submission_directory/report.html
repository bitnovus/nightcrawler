<html>
<title>Project Nightcrawler Report</title>
<h1>Project Nightcrawler Report</h1>

<p> This project was quite a journey for all of the group members.  Most of us knew little about any of the languages or applications used in this project before the beginning of this class, so we definitely learned a lot this semester. Given the amount of time that we had to develop the site and our novice standing coming into the project, our project worked out extremely well. We met all of our goals and milestones from our original proposal, even with all of the speed bumps that we encountered along the way. We chose a rather challenging project (not one that used a lot of previously written open-source or Princeton-available code) which allowed us to gain more experience. Since there were no APIs available we had to develop our own suite of scripts for data collection. </p>

<p><b> Milestones</b><br>
From our original design document, our milestones were:<br>
<ul>
	<li> Create a unified data format for travel resources. (This ended up being our dictionary entries generated on the backend and passed to the frontend to return results from all of the various travel service providers)</li>
	<li> Implement functions to access buses: Bolt Bus, Megabus, and Suburban </li>
	<li> Implement functions to access trains: NJ Transit, MTA, and Amtrak</li>
	<li> Implement functions to access more buses: Lucky Star</li>
	<li> Create search functionality</li>
	<li> Implement customer-facing interface </li>
	<li> Launch Alpha Test</li>
	<li> Launch Beta Test</li>
</ul>
Overall, we did a good job of accomplishing the milestones that we established at the beginning of the project. We ended up using Orbitz instead of SkyScanner to access flight information since SkyScanner recenlty got rid of their API.  Due to the lack of available APIs and the time-consuming nature of scraping each travel site individually, we were not able to include as many bus and train services as we had originally hoped. We gathered data from the main bus and train services: Megabus, Amtrak, and NJ Transit and incorporated this data into our website. The results returned on our site capitalize on the fact that we have aggregated information from multiple flight, train, and bus travel services. We went beyond our original milestone and were able to add a map feature to show a visual depiction of the returned results. In a sense, we exceeded our milestones. 
</p>

<p><b> Design and Interface Experience</b><br> As a group, we had very little design experience coming into the project. We learned how to use CSS this semester since we used it to style our site. We chose to give our website a relatively simple and neat appearance, which makes using our site an easier experience. Our users come to Project Nightcrawler for the specific purpose of finding cheaper, faster, smarter travel, so we tried to eliminate all superfluous links, images, buttons, etc. to improve user experience. Our goal was to make use our site as intuitive as possible. To that end, we used Twitter Bootstrap and JQuery to help us create the interface for our site, making use of standard features like autocomplete and a pop-up calendar. One of the most challenging aspects of designing the interface was centering everything on the page and making sure that the page continued to look decent as the browser window was expanded and contracted. We designed a logo that typifies the goals of our site: combinining plane, train, and bus travel in a timely manner (not the hourglass shape of our logo). </p>

<p><b> Testing</b><br> Due to the wide variety of journeys generated and displayed on our results page, testing represented one of the most challenging aspects of this process. It seemed like there were always new bugs to find since our site has so many components, and sometimes fixing one bug would cause something else to break. Most of our hard-to-find bugs stemmed from the fact that we were scraping from multiple travel service providers, and trying to return results for them and display them on the map- not just for results from all of the individual travel providers (which each have their own unique challenges), but also for routes that combine multiple modes of transportation or travel providers. We had to make sure to thoroughly test every possible combination of providers to catch as many bugs as possible. A lot of bugs were found through trial and error, testing various routes on various web browsers, to make sure that:
<ol>
	<li> The results returned that used single travel providers were accurate</li>
	<li> The results using multiple travel providers were reasonable and allowed for transfer time </li>
	<li> The results were sorted appropriately </li>
	<li> The links to purchase tickets directed users to the appropriate page </li>
	<li> The map to display the route was accurate (not returning an origin or destination in India for instance)</li>
</ol>
 For instance, we had subtle bugs related to each of the following specific issues:
<ul>
	<li> NJ Transit routes with two or more required transfers </li>
	<li> Displaying maps for Megabus routes for which the bus station name is not unique (and hence the map routes us to an undesired location) </li>
	<li> Needing to use different methodologies to get the links working for all the travel providers </li>
</ul>
 Through testing we realized that some of the original assumptions that we made about specific travels services did not hold, and we had to go back and alter our code accordingly. For instance, we had originally assumed that all of the results returned by New Jersey Transit for specific date, origin, and destination would contain the same number of transfers. This turned out not to be the case, as we discovered through testing, and we then modified the Python scraping script accordingly such that the functionality of our script does not rely on this assumption. We also distributed the url for our site to our friends, particulary those that live in the Northeast. This was helpful because sometimes they would find a bug for a city that they were particularly interested in that we had not fully tested yet. Much of our testing was done by simply sanity checking the results. For a given query, we read the returned results and made sure they were logical. If a specific result looked questionable, we would then compare the results from on our site to the result displayed on the website of the travel service itself (such as Amtrak).  We made sure that if a user entered something incorrect in one of the fields on our site, our site does not break, but instead brings up a meaningul error message in a dialog box. We also made sure our site was not susceptible to mySql injection attacks. Since we never make any calls to the database of the form "SELECT * FROM ..." we didn't really have to worry about mySql injection attacks. </p>

<p><b> Suprises</b><br> We were suprised by the amount of scraping that was necessary for this project due to the lack of APIs available from the travel services.  New Jersey Transit has an API which we ended up not using since understanding the format of the API ended up being more complicated than scraping (we had already had practice scraping many other websites, and the NJ Transit API required parsing huge amounts of data files across different text documents). SkyScanner, which returns flight information, recently got rid of its API, as did Kayak, making data collecting for the flight component of our project more challenging and time-consuming that we had originally expected. We tried registering for flightStats, but that only gave us information about current flight schedules, rather than information about booking flights, and as such was not directly applicable to our website.</p>

<p> It was surprising to us that we had to tailor each scraping method specifically to the service that we were scraping. For example, the first site that we scraped was MegaBus, which we did by inspecting the Network when querying their website. When we found that Megabus was receiving its results by using GET requests, we assumed that we would have to use GET requests for all other services as well. However, this turned out not to be the case. None of Kayak, Amtrak, NJTransit, RouteFriend, Suburban, BoltBus, and LuckyStar services were able to return results using GET requests. It took us a while until we were able to find Orbitz, which could return flight results with GET requests. Even then, we were unsure of how to scrape requests from other services without using GET requests, and it required more time before we realized that we could also use Python to submit POST requests, which would allow us to scrape the results for NJTransit and Amtrak. Even so, our GET and POST requests are not enough to cover the majority of travel services. Many of the bus travel services do not query a server, but simply post pdf documents of their schedules online, which makes it more difficult to find a route by calling a simple function. Additionally, some web pages, such as the website for Bolt Bus, load their pages dynamically as the user types into the textbox, and thus are more difficult to analyze how to get the information.</p>

<p> Even parsing the data turned up some surprises. For example, for NJTransit, the HTML is formatted differently depending on the results. One-leg trips return a table with a three columns, whereas two-leg trips return a table with four columns, and three-leg trips return a table with five columns. We had to figure out how to format our scraper to effectively capture the information in all possible cases. In short, it required a lot of creativity, not only to figure out which method we could use to get our information, but also to analyze the HTML and format our regular expressions so that they could perfectly capture the data we were seeking, regardless of the format in which it was presented. </p>

<p>We were also suprised at the amount of work it took to get the map display working. Since there is a Google Maps API, we originally thought it would be relatively straightforward. It ended up being complex because there were many different types of input that were to be passed in to generated maps (airport code, train stations, and street adresses for some of the bus stations). We had to handle map routes with multiple legs (similar to a multistop trip), which was also challenging. Furthermore, depending on the type of route that we were handling, the journey on the map had to be displayed different: a bus route was shown as being following the normal driving routes, trains had to be aligned to follow the train routes, and flights had to be displayed as straight lines from one airport to the other. Finally, we displayed flight routes in a lighter blue color than the other mode of transportation so that they could be distinguished. </p>

<p> We were also surprised at some of the challenges that GitHub presented to us. A lot of times we would forget to pull, and then would have trouble pushing later on. There seemed to be other conflict issues with pushing using GitHub as well. It was surprising that to us that GitHub posed more challenges than we were expecting, but we learned a lot more about the repository features, and the GitHub rollback features saved us a lot of time in the long run. Overall, we are extremely glad that we used this service! </p>

<p><b> Good Choices</b><br> One good choice we made was using PGAdmin3 to manage our PostgresSQL database. PDAdmin3 allowed us to visualize and edit our database using an interface similar to Microsoft Excel. Easy manipulation of the database saved us time. </p>

<p>After a long and protracted effort, we were unable to get Beautiful Soup to work for us, so we made made a good choice in deciding to move on and try a different approach. We used POST and GET requests along with regular expressions to scrape from the travel services. Even so, while this scraping approach has better performance becuase each scraping python function is site-specific, our code is not necessarily the easiest to understand or modify due to the fact that we parsed the html for regular expressions to extract the needed travel information. Furthermore, if any of the websites decided to redesign their website and use a different series of HTML scripts to display their results, we would need to completely rewrite our scraping code.</p>

<p> Finally, using Heroku was a good choice since it made deploying very fast and simple (it only requires a push command). Using git was also extremely helpful. If a group member introduced a bug, we could just use git to roll back a few versions to get back to a working version of our site. Jquery allowed us to easily and quickly add widgets to our website, which provided a more fluid user interface.  </p>

<p><b> Bad Choices</b><br> One bad choice we made was to spend so long trying to get BeautifulSoup, a python module to scrape websites, working before eventually deciding that scraping using regular expressions was a valid and easier alternatives. One group member had trouble with her python directories which resulted in the module always being downloaded into the folder for the older version of Python, even after multiple attempts to debug the issue. We even installed a virtual machine on her computer to try to get around this seemingly simple issue. Ironically another group member, whose versions of Python were better organized, had no trouble using BeautifulSoup on the first try. </p>

<p><b> Future Directions</b><br> In the future, we would like to include results from more travel service providers on our site. This will allow us to return more journey options for our users (both direct routes and combinations generated by our algorithm). We would like to include travel results from Bolt Bus since it is Megabus's most direct competitor in providing bus travel for the Northeast. Bolt Bus and Megabus are the main two bus companies still remaining that serve the Northeast since many others were shut down for violating safety regulations following a string of deadly bus accidents in March 2013. We would also like to include on our site travel provided by MTA North, a train company that provides local service traveling north from New York City and into Connecticut.</p>

<p> In addition to adding more travel providers to our site, we would also like to work on speeding up and improving our algorithm for returning journey results. While using our website is much faster than entering your desired origin and destination into the websites of all the possible travel providers, it still takes tens of seconds for our results page to load. We are using multi-processing to speed up the process of generating results, but we would like to work on making this process even faster. We also have other ideas that we have yet to implement to make our algorithm more sophisticated. For instance, one of our group members, through personal experience realized that sometimes a cheaper flight can be attained by booking a reservation that has a layover in your desired destination and simply not traveling on the last leg of the trip. Hacks like this can be incorporated to return the cheapest travel results for our users. </p>

<p> We also would like to include functionality on our site to compare the cost of driving from the desired origin to destination to the other results returned on the page. Driving cost can be computed based on gas prices and distance traveled. This functionality is not something we were able to find on other sites, so it would be unique to our site.  Right now our site only returns results for one-way travel with the idea that if a user desires the return trip as well, doing another query on our site is straightforward. We could add functionality for finding round-trip journeys relatively easily in the future. </p>

<p> Finally, if given enough time, we believe that it would be beneficial we changed the "Origin" and "Destination" bars to allow users to enter addresses instead of cities. We could also incorporate taxi information so that users would be better able to reach their specific destination after arriving at their desired city. </p>

<p><b> What We Would Do Differently</b><br> If we could start this project over again today, we would definitely start earlier and do a better job of really researching our idea before jumping into it. This would have saved us from some of the suprises that we encountered down the road. We also would have gotten testing environments and access to the database for all group members set up earlier, which would have made it easier for us to work independently. </p>

<p><b> What We Learned</b><br> We learned about many languages, tools, and development environments, many of which we had never heard of before the start of the course. Many of us had never used Python before, and this project allowed us to dive head-first into the language. Some group members had no previous database experience before this project. We also had no experience with JQuery or Twitter Bootstrap. Many of these specific tools had a learning curve, but now that we know how to use them, making a new web service would be faster and more intuitive for us. We learned the value of open source tools that are availble through Twitter Bootstrap and JQuery (such as the calendar and autocomplete menu widgets). It was really interesting how quickly some functionality was added to our site by just plugging in these features while other components of our site which probably seem much more trivial to users took us so much more time. We also learned a lot about working in a group setting. It can sometimes be challenging to find times when everyone is free especially given our hectic lives and that some of us are early morning risers while others are night owls. Not all group members knew each other well at the beginning of the semester, so we made some great new friends by working together! </p>

</html>